2021-06-15 16:10:20,914 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-06-15 16:10:20,915 - INFO - joeynmt.data - Loading training data...
2021-06-15 16:10:21,092 - INFO - joeynmt.data - Building vocabulary...
2021-06-15 16:10:21,093 - INFO - joeynmt.data - Loading dev data...
2021-06-15 16:10:21,126 - INFO - joeynmt.data - Loading test data...
2021-06-15 16:10:21,154 - INFO - joeynmt.data - Data loaded.
2021-06-15 16:10:21,172 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-06-15 16:10:21,659 - INFO - joeynmt.model - Enc-dec model built.
2021-06-15 16:10:21,664 - INFO - joeynmt.training - Total params: 44421504
2021-06-15 16:10:21,665 - DEBUG - joeynmt.training - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'decoder.tag_dec_att.key_layer.weight', 'decoder.to_embed.weight', 'decoder.to_out.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'tag_embed.lut.weight', 'trg_embed.lut.weight']
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.name                           : ccg_transformer
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.src                       : de
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.trg                       : en
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.tag                       : tags
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.train                     : ../data/mini/train_mini
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.dev                       : ../data/full/dev_bpe
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.test                      : ../data/full/test_bpe
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.level                     : bpe
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.tag_vocab                 : ../data/full/vocab.tags
2021-06-15 16:10:21,667 - INFO - joeynmt.helpers - cfg.data.random_train_subset       : 3
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.patience              : 8
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0002
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.batch_size            : 100
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.batch_type            : token
2021-06-15 16:10:21,668 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 100
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.epochs                : 100
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 4000
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/ccg_transformer
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.use_cuda              : False
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100
2021-06-15 16:10:21,669 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : False
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-06-15 16:10:21,670 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.0
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.1
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2021-06-15 16:10:21,671 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.1
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - cfg.model.decoder.use_tags         : True
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - cfg.model.decoder.tag_embeddings.embedding_dim : 128
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - cfg.model.decoder.tag_embeddings.scale : True
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - cfg.model.decoder.tag_embeddings.dropout : 0.0
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - Data set sizes: 
	train 3,
	valid 3526,
	test 2582
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - First training example:
	[SRC] beide Finanzierungs@@ operationen haben ihren Schwerpunkt auf der Finanzierung von KMU in einem Ziel @-@ 1 @-@ Gebiet der Europ√§ischen Union und werden daher von der EIB als strategisch wichtig angesehen .
	[TRG] both operations are considered strategically important for EIB given their focus on the financing of SMEs in an objective 1 region of the European Union .
	[TAG] NP/N N (S[dcl]\NP)/(S[pss]\NP) (S[pss]\NP)/(S[adj]\NP) (S[adj]\NP)/(S[adj]\NP) S[adj]\NP ((S\NP)\(S\NP))/NP N ((S\NP)\(S\NP))/NP NP/(N/PP) (N/PP)/PP PP/NP NP/N N/PP PP/NP N (N\N)/NP NP/N N/N N/N N/PP PP/NP NP/N N/N N .
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) @-@ (6) der (7) . (8) : (9) EIB
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) . (6) : (7) of (8) , (9) EIB
2021-06-15 16:10:21,672 - INFO - joeynmt.helpers - First 10 words (tag): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) N/N (5) N (6) (NP\NP)/NP (7) NP/N (8) : (9) N/PP
2021-06-15 16:10:21,673 - INFO - joeynmt.helpers - Number of Src words (types): 70
2021-06-15 16:10:21,673 - INFO - joeynmt.helpers - Number of Trg words (types): 63
2021-06-15 16:10:21,673 - INFO - joeynmt.helpers - Number of Tags (types): 511
2021-06-15 16:10:21,673 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=70),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=63),
	tag_embed=Embeddings(embedding_dim=128, vocab_size=511),
   )
2021-06-15 16:10:21,674 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 100
	total batch size (w. parallel & accumulation): 100
2021-06-15 16:10:21,674 - INFO - joeynmt.training - EPOCH 1
