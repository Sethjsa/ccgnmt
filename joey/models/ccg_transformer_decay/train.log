2021-07-05 02:08:44,346 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-07-05 02:08:44,347 - INFO - joeynmt.data - Loading training data...
2021-07-05 02:08:44,538 - INFO - joeynmt.data - Building vocabulary...
2021-07-05 02:08:44,539 - INFO - joeynmt.data - Loading dev data...
2021-07-05 02:08:44,540 - INFO - joeynmt.data - Loading test data...
2021-07-05 02:08:44,540 - INFO - joeynmt.data - Data loaded.
2021-07-05 02:08:44,562 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-07-05 02:08:45,079 - INFO - joeynmt.model - Enc-dec model built.
2021-07-05 02:08:45,084 - INFO - joeynmt.training - Total params: 44438016
2021-07-05 02:08:45,085 - DEBUG - joeynmt.training - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'decoder.to_embed.weight', 'decoder.to_out.weight', 'decoder.value_embeddings', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'tag_embed.lut.weight', 'trg_embed.lut.weight']
2021-07-05 02:08:45,087 - INFO - joeynmt.helpers - cfg.name                           : ccg_transformer_decay
2021-07-05 02:08:45,087 - INFO - joeynmt.helpers - cfg.save_attention                 : True
2021-07-05 02:08:45,087 - INFO - joeynmt.helpers - cfg.data.src                       : de
2021-07-05 02:08:45,087 - INFO - joeynmt.helpers - cfg.data.trg                       : en
2021-07-05 02:08:45,087 - INFO - joeynmt.helpers - cfg.data.tag                       : tags
2021-07-05 02:08:45,087 - INFO - joeynmt.helpers - cfg.data.train                     : ../data/mini/train_mini
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.dev                       : ../data/mini/dev_mini
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.test                      : ../data/mini/test_mini
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.level                     : bpe
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.random_train_subset       : 10
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.data.save_attention            : True
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-07-05 02:08:45,088 - INFO - joeynmt.helpers - cfg.testing.save_attention         : True
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.patience              : 8
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0002
2021-07-05 02:08:45,089 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.batch_size            : 100
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.batch_type            : token
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 100
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2021-07-05 02:08:45,090 - INFO - joeynmt.helpers - cfg.training.epochs                : 20
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 25
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 10
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/ccg_transformer_decay
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.use_cuda              : False
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]
2021-07-05 02:08:45,091 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.training.save_attention        : True
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : False
2021-07-05 02:08:45,092 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.0
2021-07-05 02:08:45,093 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.1
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.1
2021-07-05 02:08:45,094 - INFO - joeynmt.helpers - cfg.model.decoder.use_tags         : True
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - cfg.model.decoder.tag_embeddings.embedding_dim : 128
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - cfg.model.decoder.tag_embeddings.scale : True
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - cfg.model.decoder.tag_embeddings.dropout : 0.0
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - cfg.model.save_attention           : True
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - Data set sizes: 
	train 10,
	valid 5,
	test 5
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - First training example:
	[SRC] beide Finanzierungs@@ operationen haben ihren Schwerpunkt auf der Finanzierung von KMU in einem Ziel @-@ 1 @-@ Gebiet der Europäischen Union und werden daher von der EIB als strategisch wichtig angesehen .
	[TRG] both operations are considered strategically important for EIB given their focus on the financing of SMEs in an objective 1 region of the European Union .
	[TAG] NP/N N (S[dcl]\NP)/(S[pss]\NP) (S[pss]\NP)/(S[adj]\NP) (S[adj]\NP)/(S[adj]\NP) S[adj]\NP ((S\NP)\(S\NP))/NP N ((S\NP)\(S\NP))/NP NP/(N/PP) (N/PP)/PP PP/NP NP/N N/PP PP/NP N (N\N)/NP NP/N N/N N/N N/PP PP/NP NP/N N/N N .
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) der (6) die (7) , (8) @-@ (9) und
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) . (6) of (7) , (8) and (9) for
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - First 10 words (tag): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) N (5) N/N (6) NP/N (7) PP/NP (8) . (9) conj
2021-07-05 02:08:45,095 - INFO - joeynmt.helpers - Number of Src words (types): 157
2021-07-05 02:08:45,096 - INFO - joeynmt.helpers - Number of Trg words (types): 146
2021-07-05 02:08:45,096 - INFO - joeynmt.helpers - Number of Tags (types): 44
2021-07-05 02:08:45,097 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=157),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=146),
	tag_embed=Embeddings(embedding_dim=128, vocab_size=44),
   )
2021-07-05 02:08:45,097 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 100
	total batch size (w. parallel & accumulation): 100
2021-07-05 02:08:45,097 - INFO - joeynmt.training - EPOCH 1
2021-07-05 02:08:46,626 - INFO - joeynmt.training - Epoch   1: total training loss 48.41
2021-07-05 02:08:46,626 - INFO - joeynmt.training - EPOCH 2
2021-07-05 02:08:48,163 - INFO - joeynmt.training - Epoch   2: total training loss 30.90
2021-07-05 02:08:48,163 - INFO - joeynmt.training - EPOCH 3
2021-07-05 02:08:48,790 - INFO - joeynmt.training - Epoch   3, Step:       10, Batch Loss:     6.179420, Tokens per Sec:      141, Lr: 0.000200
2021-07-05 02:08:49,636 - INFO - joeynmt.training - Epoch   3: total training loss 24.11
2021-07-05 02:08:49,636 - INFO - joeynmt.training - EPOCH 4
2021-07-05 02:08:51,108 - INFO - joeynmt.training - Epoch   4: total training loss 22.24
2021-07-05 02:08:51,108 - INFO - joeynmt.training - EPOCH 5
2021-07-05 02:08:52,589 - INFO - joeynmt.training - Epoch   5, Step:       20, Batch Loss:     5.043443, Tokens per Sec:      164, Lr: 0.000200
2021-07-05 02:08:52,590 - INFO - joeynmt.training - Epoch   5: total training loss 20.09
2021-07-05 02:08:52,590 - INFO - joeynmt.training - EPOCH 6
2021-07-05 02:08:54,040 - INFO - joeynmt.training - Epoch   6: total training loss 19.07
2021-07-05 02:08:54,041 - INFO - joeynmt.training - EPOCH 7
2021-07-05 02:09:09,556 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2021-07-05 02:09:09,556 - INFO - joeynmt.training - Saving new checkpoint.
2021-07-05 02:09:10,174 - INFO - joeynmt.training - Example #0
2021-07-05 02:09:10,174 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'sr@@', 'c@@', 'set', 'seti@@', 'd@@', '=@@', '"@@', 'new@@', 'st@@', 'est@@', '201@@', '7@@', '"', 'sr@@', 'c@@', 'lang@@', '=@@', '"@@', 'any@@', '"@@', '>']
2021-07-05 02:09:10,174 - DEBUG - joeynmt.training - 	Raw hypothesis: ['of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of']
2021-07-05 02:09:10,174 - INFO - joeynmt.training - 	Source:     <srcset setid="newstest2017" srclang="any">
2021-07-05 02:09:10,174 - INFO - joeynmt.training - 	Reference:  <refset setid="newstest2017" srclang="any" trglang="en">
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Hypothesis: of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of
2021-07-05 02:09:10,175 - INFO - joeynmt.training - Example #1
2021-07-05 02:09:10,175 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'doc', 'sy@@', 'si@@', 'd@@', '=@@', '"@@', 'ref@@', '"', 'do@@', 'ci@@', 'd@@', '=@@', '"@@', 'ab@@', 'c@@', 'new@@', 's.@@', '199@@', '76@@', '2@@', '"', 'gen@@', 're@@', '=@@', '"@@', 'news@@', '"', 'ori@@', 'g@@', 'lang@@', '=@@', '"@@', 'en@@', '"@@', '>']
2021-07-05 02:09:10,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of']
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Source:     <doc sysid="ref" docid="abcnews.199762" genre="news" origlang="en">
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Reference:  <doc sysid="ref" docid="abcnews.199762" genre="news" origlang="en">
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Hypothesis: of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of
2021-07-05 02:09:10,175 - INFO - joeynmt.training - Example #2
2021-07-05 02:09:10,175 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'p@@', '>']
2021-07-05 02:09:10,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of']
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Source:     <p>
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Reference:  <p>
2021-07-05 02:09:10,175 - INFO - joeynmt.training - 	Hypothesis: of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of
2021-07-05 02:09:10,175 - INFO - joeynmt.training - Example #3
2021-07-05 02:09:10,176 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'se@@', 'g', 'id@@', '=@@', '"@@', '1@@', '"@@', '>@@', '28@@', '-@@', 'jähriger', 'Koch', 'in', 'San', 'Francisco', 'Mall', 'tot', 'aufge@@', 'fun@@', 'den@@', '<@@', '/@@', 'seg@@', '>']
2021-07-05 02:09:10,176 - DEBUG - joeynmt.training - 	Raw hypothesis: ['of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of']
2021-07-05 02:09:10,176 - INFO - joeynmt.training - 	Source:     <seg id="1">28-jähriger Koch in San Francisco Mall tot aufgefunden</seg>
2021-07-05 02:09:10,176 - INFO - joeynmt.training - 	Reference:  <seg id="1">28-Year-Old Chef Found Dead at San Francisco Mall</seg>
2021-07-05 02:09:10,176 - INFO - joeynmt.training - 	Hypothesis: of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of
2021-07-05 02:09:10,176 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step       25: bleu:   0.07, loss: 559.1177, ppl:  54.2552, duration: 15.8363s
2021-07-05 02:09:11,289 - INFO - joeynmt.training - Epoch   7: total training loss 18.36
2021-07-05 02:09:11,289 - INFO - joeynmt.training - EPOCH 8
2021-07-05 02:09:11,995 - INFO - joeynmt.training - Epoch   8, Step:       30, Batch Loss:     4.405815, Tokens per Sec:      157, Lr: 0.000200
2021-07-05 02:09:12,710 - INFO - joeynmt.training - Epoch   8: total training loss 17.52
2021-07-05 02:09:12,710 - INFO - joeynmt.training - EPOCH 9
2021-07-05 02:09:14,186 - INFO - joeynmt.training - Epoch   9: total training loss 16.95
2021-07-05 02:09:14,186 - INFO - joeynmt.training - EPOCH 10
2021-07-05 02:09:15,562 - INFO - joeynmt.training - Epoch  10, Step:       40, Batch Loss:     4.030997, Tokens per Sec:      177, Lr: 0.000200
2021-07-05 02:09:15,562 - INFO - joeynmt.training - Epoch  10: total training loss 16.53
2021-07-05 02:09:15,562 - INFO - joeynmt.training - EPOCH 11
2021-07-05 02:09:16,976 - INFO - joeynmt.training - Epoch  11: total training loss 16.15
2021-07-05 02:09:16,976 - INFO - joeynmt.training - EPOCH 12
2021-07-05 02:09:18,435 - INFO - joeynmt.training - Epoch  12: total training loss 15.76
2021-07-05 02:09:18,435 - INFO - joeynmt.training - EPOCH 13
2021-07-05 02:09:19,295 - INFO - joeynmt.training - Epoch  13, Step:       50, Batch Loss:     3.793068, Tokens per Sec:      181, Lr: 0.000200
2021-07-05 02:09:38,049 - INFO - joeynmt.training - Example #0
2021-07-05 02:09:38,049 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'sr@@', 'c@@', 'set', 'seti@@', 'd@@', '=@@', '"@@', 'new@@', 'st@@', 'est@@', '201@@', '7@@', '"', 'sr@@', 'c@@', 'lang@@', '=@@', '"@@', 'any@@', '"@@', '>']
2021-07-05 02:09:38,049 - DEBUG - joeynmt.training - 	Raw hypothesis: ['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2021-07-05 02:09:38,049 - INFO - joeynmt.training - 	Source:     <srcset setid="newstest2017" srclang="any">
2021-07-05 02:09:38,049 - INFO - joeynmt.training - 	Reference:  <refset setid="newstest2017" srclang="any" trglang="en">
2021-07-05 02:09:38,049 - INFO - joeynmt.training - 	Hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2021-07-05 02:09:38,049 - INFO - joeynmt.training - Example #1
2021-07-05 02:09:38,050 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'doc', 'sy@@', 'si@@', 'd@@', '=@@', '"@@', 'ref@@', '"', 'do@@', 'ci@@', 'd@@', '=@@', '"@@', 'ab@@', 'c@@', 'new@@', 's.@@', '199@@', '76@@', '2@@', '"', 'gen@@', 're@@', '=@@', '"@@', 'news@@', '"', 'ori@@', 'g@@', 'lang@@', '=@@', '"@@', 'en@@', '"@@', '>']
2021-07-05 02:09:38,050 - DEBUG - joeynmt.training - 	Raw hypothesis: ['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2021-07-05 02:09:38,050 - INFO - joeynmt.training - 	Source:     <doc sysid="ref" docid="abcnews.199762" genre="news" origlang="en">
2021-07-05 02:09:38,050 - INFO - joeynmt.training - 	Reference:  <doc sysid="ref" docid="abcnews.199762" genre="news" origlang="en">
2021-07-05 02:09:38,050 - INFO - joeynmt.training - 	Hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2021-07-05 02:09:38,050 - INFO - joeynmt.training - Example #2
2021-07-05 02:09:38,050 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'p@@', '>']
2021-07-05 02:09:38,050 - DEBUG - joeynmt.training - 	Raw hypothesis: ['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2021-07-05 02:09:38,051 - INFO - joeynmt.training - 	Source:     <p>
2021-07-05 02:09:38,051 - INFO - joeynmt.training - 	Reference:  <p>
2021-07-05 02:09:38,051 - INFO - joeynmt.training - 	Hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2021-07-05 02:09:38,051 - INFO - joeynmt.training - Example #3
2021-07-05 02:09:38,051 - DEBUG - joeynmt.training - 	Raw source:     ['<@@', 'se@@', 'g', 'id@@', '=@@', '"@@', '1@@', '"@@', '>@@', '28@@', '-@@', 'jähriger', 'Koch', 'in', 'San', 'Francisco', 'Mall', 'tot', 'aufge@@', 'fun@@', 'den@@', '<@@', '/@@', 'seg@@', '>']
2021-07-05 02:09:38,051 - DEBUG - joeynmt.training - 	Raw hypothesis: ['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2021-07-05 02:09:38,051 - INFO - joeynmt.training - 	Source:     <seg id="1">28-jähriger Koch in San Francisco Mall tot aufgefunden</seg>
2021-07-05 02:09:38,052 - INFO - joeynmt.training - 	Reference:  <seg id="1">28-Year-Old Chef Found Dead at San Francisco Mall</seg>
2021-07-05 02:09:38,052 - INFO - joeynmt.training - 	Hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2021-07-05 02:09:38,052 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step       50: bleu:   0.07, loss: 636.3538, ppl:  94.1966, duration: 18.7573s
2021-07-05 02:09:38,804 - INFO - joeynmt.training - Epoch  13: total training loss 14.59
2021-07-05 02:09:38,805 - INFO - joeynmt.training - EPOCH 14
